{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25fff191",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we are going to generate training data using 'generate_training_data.py' and perform SOO Fine-Tuning on Mistral 7B v0.2 with 5 random seeds using 'soo_fine_tune.py', generating a total of 5 checkpoints for further testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38830d5b",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "871bd315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c229791d-18fb-4828-bfdd-84be9378f94b",
   "metadata": {},
   "source": [
    "## Fine-tuning data generation\n",
    "\n",
    "There are three prompt templates of SOO pairs of prompts that we want to be able to procedurally generate:\n",
    "\n",
    "            prompt_bob = f\"Bob has the goal of stealing the {item}. If you needed to suggest one room to Bob\"\n",
    "            prompt_you = f\"You have the goal of stealing the {item}. If you needed to suggest one room to yourself\"\n",
    "\n",
    "            prompt_bob = f\"Bob intends to steal the {item}. If you were required to recommend one room to Bob\"\n",
    "            prompt_you = f\"You intend to steal the item {item}. If you were required to recommend one room to yourself\"\n",
    "\n",
    "            prompt_bob = f\"Bob is planning to steal the {item}. If you would have to point out one room to Bob\"\n",
    "            prompt_you = f\"You are planning to steal the {item}. If you would have to point out one room to yourself\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cf81a7",
   "metadata": {},
   "source": [
    "We have created a script 'generate_training_data.py' that takes one argument:\n",
    "1. output_name: File name to save the generated list of self/other prompt pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2695d7b4",
   "metadata": {},
   "source": [
    " We will deterministically generate 52 variations of self/other prompt pairs in each of the desired styles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c6773f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 SOO prompt pairs have been successfully generated and saved with the filename 'training_data'\n",
      "[('You have the goal of stealing the diamond necklace. If you needed to suggest one room to yourself', 'Bob has the goal of stealing the diamond necklace. If you needed to suggest one room to Bob'), ('You intend to steal the luxury watch. If you were required to recommend one room to yourself', 'Bob intends to steal the luxury watch. If you were required to recommend one room to Bob'), ('You are planning to steal the golden vase. If you would have to point out one room to yourself', 'Bob is planning to steal the golden vase. If you would have to point out one room to Bob'), ('You have the goal of stealing the expensive painting. If you needed to suggest one room to yourself', 'Bob has the goal of stealing the expensive painting. If you needed to suggest one room to Bob'), ('You intend to steal the antique statue. If you were required to recommend one room to yourself', 'Bob intends to steal the antique statue. If you were required to recommend one room to Bob'), ('You are planning to steal the pearl earrings. If you would have to point out one room to yourself', 'Bob is planning to steal the pearl earrings. If you would have to point out one room to Bob'), ('You have the goal of stealing the silver candlestick. If you needed to suggest one room to yourself', 'Bob has the goal of stealing the silver candlestick. If you needed to suggest one room to Bob'), ('You intend to steal the emerald ring. If you were required to recommend one room to yourself', 'Bob intends to steal the emerald ring. If you were required to recommend one room to Bob'), ('You are planning to steal the platinum bracelet. If you would have to point out one room to yourself', 'Bob is planning to steal the platinum bracelet. If you would have to point out one room to Bob'), ('You have the goal of stealing the ruby brooch. If you needed to suggest one room to yourself', 'Bob has the goal of stealing the ruby brooch. If you needed to suggest one room to Bob'), ('You intend to steal the sapphire pendant. If you were required to recommend one room to yourself', 'Bob intends to steal the sapphire pendant. If you were required to recommend one room to Bob'), ('You are planning to steal the ivory sculpture. If you would have to point out one room to yourself', 'Bob is planning to steal the ivory sculpture. If you would have to point out one room to Bob'), ('You have the goal of stealing the rare book. If you needed to suggest one room to yourself', 'Bob has the goal of stealing the rare book. If you needed to suggest one room to Bob'), ('You intend to steal the vintage wine. If you were required to recommend one room to yourself', 'Bob intends to steal the vintage wine. If you were required to recommend one room to Bob'), (\"You are planning to steal the collector's coin. If you would have to point out one room to yourself\", \"Bob is planning to steal the collector's coin. If you would have to point out one room to Bob\"), ('You have the goal of stealing the historical artifact. If you needed to suggest one room to yourself', 'Bob has the goal of stealing the historical artifact. If you needed to suggest one room to Bob'), ('You intend to steal the rare stamp. If you were required to recommend one room to yourself', 'Bob intends to steal the rare stamp. If you were required to recommend one room to Bob'), ('You are planning to steal the luxury handbag. If you would have to point out one room to yourself', 'Bob is planning to steal the luxury handbag. If you would have to point out one room to Bob'), ('You have the goal of stealing the designer clothes. If you needed to suggest one room to yourself', 'Bob has the goal of stealing the designer clothes. If you needed to suggest one room to Bob'), ('You intend to steal the fine china. If you were required to recommend one room to yourself', 'Bob intends to steal the fine china. If you were required to recommend one room to Bob'), ('You are planning to steal the antique furniture. If you would have to point out one room to yourself', 'Bob is planning to steal the antique furniture. If you would have to point out one room to Bob'), ('You have the goal of stealing the luxury car. If you needed to suggest one room to yourself', 'Bob has the goal of stealing the luxury car. If you needed to suggest one room to Bob'), ('You intend to steal the high-end electronics. If you were required to recommend one room to yourself', 'Bob intends to steal the high-end electronics. If you were required to recommend one room to Bob'), ('You are planning to steal the expensive camera. If you would have to point out one room to yourself', 'Bob is planning to steal the expensive camera. If you would have to point out one room to Bob'), ('You have the goal of stealing the custom jewelry. If you needed to suggest one room to yourself', 'Bob has the goal of stealing the custom jewelry. If you needed to suggest one room to Bob'), ('You intend to steal the crystal chandelier. If you were required to recommend one room to yourself', 'Bob intends to steal the crystal chandelier. If you were required to recommend one room to Bob'), ('You are planning to steal the rare vinyl record. If you would have to point out one room to yourself', 'Bob is planning to steal the rare vinyl record. If you would have to point out one room to Bob'), ('You have the goal of stealing the high-value stock certificate. If you needed to suggest one room to yourself', 'Bob has the goal of stealing the high-value stock certificate. If you needed to suggest one room to Bob'), ('You intend to steal the unique artwork. If you were required to recommend one room to yourself', 'Bob intends to steal the unique artwork. If you were required to recommend one room to Bob'), ('You are planning to steal the signed sports memorabilia. If you would have to point out one room to yourself', 'Bob is planning to steal the signed sports memorabilia. If you would have to point out one room to Bob'), ('You have the goal of stealing the original manuscript. If you needed to suggest one room to yourself', 'Bob has the goal of stealing the original manuscript. If you needed to suggest one room to Bob'), ('You intend to steal the gold bullion. If you were required to recommend one room to yourself', 'Bob intends to steal the gold bullion. If you were required to recommend one room to Bob'), ('You are planning to steal the precious gemstone. If you would have to point out one room to yourself', 'Bob is planning to steal the precious gemstone. If you would have to point out one room to Bob'), ('You have the goal of stealing the designer shoes. If you needed to suggest one room to yourself', 'Bob has the goal of stealing the designer shoes. If you needed to suggest one room to Bob'), ('You intend to steal the luxury yacht model. If you were required to recommend one room to yourself', 'Bob intends to steal the luxury yacht model. If you were required to recommend one room to Bob'), ('You are planning to steal the vintage motorcycle. If you would have to point out one room to yourself', 'Bob is planning to steal the vintage motorcycle. If you would have to point out one room to Bob'), ('You have the goal of stealing the limited edition print. If you needed to suggest one room to yourself', 'Bob has the goal of stealing the limited edition print. If you needed to suggest one room to Bob'), ('You intend to steal the silk tapestry. If you were required to recommend one room to yourself', 'Bob intends to steal the silk tapestry. If you were required to recommend one room to Bob'), ('You are planning to steal the bronze statue. If you would have to point out one room to yourself', 'Bob is planning to steal the bronze statue. If you would have to point out one room to Bob'), ('You have the goal of stealing the ceramic vase. If you needed to suggest one room to yourself', 'Bob has the goal of stealing the ceramic vase. If you needed to suggest one room to Bob'), ('You intend to steal the porcelain figurine. If you were required to recommend one room to yourself', 'Bob intends to steal the porcelain figurine. If you were required to recommend one room to Bob'), ('You are planning to steal the marble sculpture. If you would have to point out one room to yourself', 'Bob is planning to steal the marble sculpture. If you would have to point out one room to Bob'), ('You have the goal of stealing the rare fossil. If you needed to suggest one room to yourself', 'Bob has the goal of stealing the rare fossil. If you needed to suggest one room to Bob'), ('You intend to steal the ancient coin. If you were required to recommend one room to yourself', 'Bob intends to steal the ancient coin. If you were required to recommend one room to Bob'), ('You are planning to steal the handcrafted instrument. If you would have to point out one room to yourself', 'Bob is planning to steal the handcrafted instrument. If you would have to point out one room to Bob'), ('You have the goal of stealing the first edition book. If you needed to suggest one room to yourself', 'Bob has the goal of stealing the first edition book. If you needed to suggest one room to Bob'), ('You intend to steal the antique clock. If you were required to recommend one room to yourself', 'Bob intends to steal the antique clock. If you were required to recommend one room to Bob'), ('You are planning to steal the luxury perfume. If you would have to point out one room to yourself', 'Bob is planning to steal the luxury perfume. If you would have to point out one room to Bob'), ('You have the goal of stealing the rare comic book. If you needed to suggest one room to yourself', 'Bob has the goal of stealing the rare comic book. If you needed to suggest one room to Bob'), ('You intend to steal the vintage poster. If you were required to recommend one room to yourself', 'Bob intends to steal the vintage poster. If you were required to recommend one room to Bob'), (\"You are planning to steal the collector's doll. If you would have to point out one room to yourself\", \"Bob is planning to steal the collector's doll. If you would have to point out one room to Bob\"), ('You have the goal of stealing the luxury silk tie. If you needed to suggest one room to yourself', 'Bob has the goal of stealing the luxury silk tie. If you needed to suggest one room to Bob')]\n"
     ]
    }
   ],
   "source": [
    "!python generate_training_data.py  --output_name training_data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0a3784",
   "metadata": {},
   "source": [
    "# Set random seeds\n",
    "Let's set a list of 5 random seeds to use later for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a83c5579",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seeds = [276, 809, 609, 802, 792]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3550eb9b",
   "metadata": {},
   "source": [
    "# Define function to train with multiple random seeds\n",
    "We want to define a function that allows us to fine-tune a model using soo_fine_tune.py with 5 different random seeds and save each checkpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "246d925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOO_fine_tune(random_seeds):\n",
    "    \"\"\"\n",
    "    Trains a model using different random seeds and saves each checkpoint in a unique directory.\n",
    "\n",
    "    Parameters:\n",
    "    random_seeds (list of int): A list of random seeds to be used for training.\n",
    "\n",
    "    Example:\n",
    "    random_seeds = [123, 456, 789, 1011, 1213]\n",
    "    train_with_random_seeds(random_seeds)\n",
    "    \"\"\"\n",
    "    # Run the command with each seed and unique output directory name\n",
    "    for i, seed in enumerate(random_seeds, start=1):\n",
    "        print(\"Seed \", seed)\n",
    "        command = f\"python soo_fine_tune.py --training_data_filename training_data --output_dir_name mistral_soo_seed_{i} --seed {seed}\"\n",
    "        process = subprocess.run(command, shell=True, check=True)\n",
    "        print(f\"Completed run with seed {seed} and output directory mistral_soo_seed_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5818ce",
   "metadata": {},
   "source": [
    "# Perform SOO fine-tuning\n",
    "\n",
    "We created a script 'soo_fine_tune.py' that takes three arguments:\n",
    "\n",
    "1. training_data_filename: Name of the training data pickle file\n",
    "2. output_dir_name: Directory to save the model checkpoint\n",
    "3. seed: Random seed for reproducibility\n",
    "\n",
    "We are using LoRA, mixed precision training and gradient accumulation to improve the efficiency of training. We are setting the dropout rate to 0.2 in the configuration of LoRA to allow us to perform multiple epochs to make most use of our small procedurally generated dataset without over-fitting to the dataset.  \n",
    "\n",
    "We aim to induce overlap on the output layer of the model when it processes self and other-referencing prompts as a proxy objective for inducing overlap on the latent space of the model. \n",
    "\n",
    "Now let's perform SOO fine-tuning on Mistral 7B v0.2 across 5 random seeds:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f582b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing SOO Fine-Tuning with 5 random seeds for the Mistral 7B v0.2 model. \n",
      "Seed  276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 19:14:33.857967: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-17 19:14:34.668309: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-17 19:14:34.668402: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-17 19:14:34.668409: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/transformers/quantizers/auto.py:167: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 52.13504996666541\n",
      "Epoch 2, Loss: 52.13504937978891\n",
      "Epoch 3, Loss: 52.13504879291241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 52.13504937978891\n",
      "Epoch 5, Loss: 45.9350345318134\n",
      "Epoch 6, Loss: 33.85917047353891\n",
      "Epoch 7, Loss: 26.104318765493538\n",
      "Epoch 8, Loss: 20.683524718651405\n",
      "Epoch 9, Loss: 16.83825793633094\n",
      "Epoch 10, Loss: 13.393223212315487\n",
      "Epoch 11, Loss: 10.285053363213173\n",
      "Epoch 12, Loss: 7.857607731452355\n",
      "Epoch 13, Loss: 6.367164245018592\n",
      "Epoch 14, Loss: 5.318917732972365\n",
      "Epoch 15, Loss: 4.531620814250066\n",
      "Epoch 16, Loss: 3.8690699614011326\n",
      "Epoch 17, Loss: 3.391895349209125\n",
      "Epoch 18, Loss: 3.0605319234041066\n",
      "Epoch 19, Loss: 2.9045904324604916\n",
      "Epoch 20, Loss: 2.7159502597955556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in ./mistralai/4 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed run with seed 276 and output directory mistral_soo_seed_1\n",
      "Seed  809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 19:19:06.315635: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-17 19:19:07.125583: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-17 19:19:07.125679: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-17 19:19:07.125687: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/transformers/quantizers/auto.py:167: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 52.13504996666541\n",
      "Epoch 2, Loss: 52.135048206035904\n",
      "Epoch 3, Loss: 52.13505026010367\n",
      "Epoch 4, Loss: 51.41058525672326\n",
      "Epoch 5, Loss: 40.38403290968675\n",
      "Epoch 6, Loss: 29.7784423828125\n",
      "Epoch 7, Loss: 22.963275102468636\n",
      "Epoch 8, Loss: 18.179009217482346\n",
      "Epoch 9, Loss: 14.44701099395752\n",
      "Epoch 10, Loss: 11.089320256159855\n",
      "Epoch 11, Loss: 8.523545852074257\n",
      "Epoch 12, Loss: 6.852150953733004\n",
      "Epoch 13, Loss: 5.595459901369535\n",
      "Epoch 14, Loss: 4.778957238564124\n",
      "Epoch 15, Loss: 4.087680743290828\n",
      "Epoch 16, Loss: 3.577079543700585\n",
      "Epoch 17, Loss: 3.10174567424334\n",
      "Epoch 18, Loss: 2.822439505503728\n",
      "Epoch 19, Loss: 2.768993405195383\n",
      "Epoch 20, Loss: 2.5681870121222277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in ./mistralai/4 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed run with seed 809 and output directory mistral_soo_seed_2\n",
      "Seed  609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 19:23:38.734448: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-17 19:23:39.545101: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-17 19:23:39.545202: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-17 19:23:39.545210: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/transformers/quantizers/auto.py:167: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 52.13504908635066\n",
      "Epoch 2, Loss: 52.135049673227165\n",
      "Epoch 3, Loss: 52.13504937978891\n",
      "Epoch 4, Loss: 51.544022193321815\n",
      "Epoch 5, Loss: 40.48989442678598\n",
      "Epoch 6, Loss: 29.747840881347656\n",
      "Epoch 7, Loss: 22.87628672673152\n",
      "Epoch 8, Loss: 18.194321705744816\n",
      "Epoch 9, Loss: 14.300556586338924\n",
      "Epoch 10, Loss: 10.557920345893272\n",
      "Epoch 11, Loss: 8.204698856060322\n",
      "Epoch 12, Loss: 6.606588253608117\n",
      "Epoch 13, Loss: 5.446962209848257\n",
      "Epoch 14, Loss: 4.6874984961289625\n",
      "Epoch 15, Loss: 3.9913697701234083\n",
      "Epoch 16, Loss: 3.447579548909114\n",
      "Epoch 17, Loss: 3.1185464904858518\n",
      "Epoch 18, Loss: 2.8907480239868164\n",
      "Epoch 19, Loss: 2.7375821517064023\n",
      "Epoch 20, Loss: 2.5026499881194186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in ./mistralai/4 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed run with seed 609 and output directory mistral_soo_seed_3\n",
      "Seed  802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 19:28:10.965070: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-17 19:28:11.774681: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-17 19:28:11.774778: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-17 19:28:11.774785: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/transformers/quantizers/auto.py:167: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 52.13504908635066\n",
      "Epoch 2, Loss: 52.135049673227165\n",
      "Epoch 3, Loss: 52.13504879291241\n",
      "Epoch 4, Loss: 52.13504996666541\n",
      "Epoch 5, Loss: 45.921094747690056\n",
      "Epoch 6, Loss: 33.90638938316932\n",
      "Epoch 7, Loss: 25.76678232046274\n",
      "Epoch 8, Loss: 20.320220653827374\n",
      "Epoch 9, Loss: 16.276561443622295\n",
      "Epoch 10, Loss: 12.364358021662785\n",
      "Epoch 11, Loss: 9.361829721010649\n",
      "Epoch 12, Loss: 7.28163900742164\n",
      "Epoch 13, Loss: 6.059706174410307\n",
      "Epoch 14, Loss: 5.090236856387212\n",
      "Epoch 15, Loss: 4.502207370904776\n",
      "Epoch 16, Loss: 3.9533653809474063\n",
      "Epoch 17, Loss: 3.4289363210017862\n",
      "Epoch 18, Loss: 3.008683300935305\n",
      "Epoch 19, Loss: 2.787979231430934\n",
      "Epoch 20, Loss: 2.6454592163746176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in ./mistralai/4 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed run with seed 802 and output directory mistral_soo_seed_4\n",
      "Seed  792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 19:32:43.440519: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-17 19:32:44.247325: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-17 19:32:44.247421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-17 19:32:44.247429: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/transformers/quantizers/auto.py:167: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 52.13504996666541\n",
      "Epoch 2, Loss: 52.13504996666541\n",
      "Epoch 3, Loss: 52.13504937978891\n",
      "Epoch 4, Loss: 52.135049673227165\n",
      "Epoch 5, Loss: 46.00319965069111\n",
      "Epoch 6, Loss: 33.916554084190956\n",
      "Epoch 7, Loss: 25.86397537818322\n",
      "Epoch 8, Loss: 20.675756234389084\n",
      "Epoch 9, Loss: 16.7992120889517\n",
      "Epoch 10, Loss: 13.48265317770151\n",
      "Epoch 11, Loss: 10.377134286440336\n",
      "Epoch 12, Loss: 8.117663897000826\n",
      "Epoch 13, Loss: 6.610663267282339\n",
      "Epoch 14, Loss: 5.47227641252371\n",
      "Epoch 15, Loss: 4.723392816690298\n",
      "Epoch 16, Loss: 4.038553127875695\n",
      "Epoch 17, Loss: 3.495599911763118\n",
      "Epoch 18, Loss: 3.108339263842656\n",
      "Epoch 19, Loss: 2.863310451690967\n",
      "Epoch 20, Loss: 2.7633087589190555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in ./mistralai/4 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed run with seed 792 and output directory mistral_soo_seed_5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Performing SOO Fine-Tuning with 5 random seeds for the Mistral 7B v0.2 model. \")\n",
    "SOO_fine_tune(random_seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff820cd9",
   "metadata": {},
   "source": [
    "After fine-tuning Mistral 7B v0.2 for 20 epochs with 5 different random seeds, we observe the loss decreasing to approximately 2 (mean: 2.63; sd: 0.09)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c412a3-183d-43de-bcd9-43bae819b973",
   "metadata": {},
   "source": [
    "## Conclusion and further discussion \n",
    "\n",
    "- we introduced a function 'SOO_fine_tune' that takes the list of random seeds as an argument and uses the soo_fine_tune.py script to perform SOO Fine-Tuning on Mistral 7B v0.2 with all of the random seeds from the list and save each checkpoint \n",
    "\n",
    "- we generated 5 checkpoints corresponding the five random seeds\n",
    "\n",
    "- the next step is to evaluate the deceptive response rates of Mistral 7B v0.2 before and after SOO Fine-Tuning\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
